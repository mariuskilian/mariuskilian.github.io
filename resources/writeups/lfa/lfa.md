
**Abstract —** A reinforcement learning (RL) using linear function approximation and Q-learning is explored in the Tabletop Games Framework (TAG), a Java framework for artificial intelligence in tabletop games. Linear function approximation RL allows training on rich dynamic action spaces that board games can offer, while providing transparent and interpretable results, giving insight into the agent’s “thought process”. Implementing the agent in TAG takes advantage of the extensive library of board games that are implemented in TAG, as well as the numerous types of search agents, allowing the RL agent to be compared against many methods in many environments. Further, a direct comparison between search-based agent and the planning-based RL agent is possible. Here, the RL agent is tested in three game, Tic-Tac-Toe, Dots and Boxes and Sushi Go, against different Monte-Carlo Tree Search agents. While it reaches high performance in Dots and Boxes, it does not perform nearly as well in the other two games. The overall performance in all games based on amount of training is inconsistent and unpredictable. Generally, the agent still shows potential to be a well-playing artificial intelligence agent for the framework, but needs adjusting in the methods used for its training, as well as the extent of its training.
<br /><br />